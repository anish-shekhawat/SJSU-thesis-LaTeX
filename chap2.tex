\chapter{Related Work\label{chap:related}}

Traditional malicious network communication techniques rely either on port-based classification or deep packet inspection and signature matching techniques. Port-based methods rely on inspection of Transmission Control Protocol (TCP) or User Datagram Protocol (UDP) port numbers~\cite{YoonPPOK09} and assumption that applications always use well-known port numbers that are registered by the Internet Assigned Numbers Authority (IANA)~\cite{IANA}. Dreger and Feldmann in~\cite{DregerF06} showed that malicious applications use non-standard ports to evade network intrusion detection systems (NIDS) and restricting firewalls. Even prominent applications such as Skype use dynamic port numbers to escape restrictive firewalls~\cite{BasetS06}. Madhukar and Williamson in~\cite{MadhukarW06} showed that port-based classification mis-classifies network flow traffic 30-70\% of the time. 

Etienne in~\cite{Etienne} used deep packet inspection to detect malicious traffic. He inspected the packet contents and used traditional pattern matching or signature based detection to detect if the packet is malicious. He used Sort~\cite{Snort}, an intrusion detection application, to detect malicious traffic using signature or string matching on the packet contents. Snort also hosts a popular Intrusion Protection System (IPS) rule set maintained by the community~\cite{SnortCR}. But only around 1 \% of the rule set are TLS specific which shows that traditional pattern matching techniques are not used often for TLS based malware. Sen \etal~\cite{SenSW04} demonstrates the use of deep packet inspection to reduce false positive and false negative rates by 5\% when classifying Peer-to-Peer (P2P) traffic. Moore and Papagiannaki in~\cite{MooreP05} achieved a 100\% accuracy when identifying network applications using the entire packet payload. The primary limitations of these methods are the invasion of user privacy and the huge overhead of decrypting and analyzing each packet.

Tegeler \etal in~\cite{TegelerFVK12} presented BotFinder, a network-flow information based system to detect bot infections. The system uses a sequence of chronologically-ordered flow called traces to find irregularities in the network behavior between two endpoints. This along with other network metadata such as average time interval, averaged duration, average number of source and destination bytes, etc. were used as features in a local shrinking based clustering algorithm~\cite{WangQZ07}. Prasse \etal in~\cite{PrasseMPHS17} derived a neural network based malware detection using network flow features such as port value, connection duration, number of bytes sent and received, time interval between packets and domain name features. We do not use domain name features or Domain Name System (DNS) data as features due to the introduction of DNS over TLS where the DNS data is also encrypted using TLS~\cite{Hu16a}. Loko\v c \etal in~\cite{LokocKCSP16} presented a k-NN based classification technique that could identify servers contacted by malware using HTTPS traffic. Anderson and McGrew in~\cite{AndersonM17} proposed a new technique that analyzed network flow metadata and applied supervised machine learning algorithms to identify encrypted malware traffic. They used a demilitarized zone (DMZ), to collect and train the machine learning algorithm on the benign network traffic. DMZ is a sub-network that separates the externally connected services from internal systems. Externally connected services are those which connect to the internet to provide various services. As it was based on supervised learning models, it provided results which can be easily interpreted~\cite{SommerP10}. The machine learning model helped in high-speed processing of the network traffic and real-time predictions. It also leveraged regularization, an important part of training, to select features that are most discriminatory~\cite{HastieTF09}. Since the DMZ segregates such services and is used only in business organizations, the network traffic data collected by them is not an actual representation of the general network traffic. Since this data represents only enterprise users, i.e. those who work in business organizations, the results may not hold for general internet users such as students or home users as mentioned in~\cite{AndersonM17}.

This paper further explores the use of network flow information as features which can be used to train machine learning algorithms. These features are obtained without decrypting any packets in the flow.
