\chapter{Related Work\label{chap:related}}

Traditional malicious traffic detection techniques rely on port based detection or deep packet inspection of network traffic payload and signature matching techniques. 

Etienne in \cite{Etienne} used deep packet inspection to detect malicious traffic. He inspected the packet contents and used traditional pattern matching or signature based detection to detect if the packet is malicious. He used Sort \cite{Snort}, an intrusion detection application, to detect malicious traffic using signature or string matching on the packet contents. Snort also hosts a popular Intrusion Protection System (IPS) rule set maintained by the community \cite{SnortCR}. But only around 1 \% of the rule set are TLS specific which shows that traditional pattern matching techniques are not used often for TLS based malware. The primary limitations of these methods are the invasion of user privacy and the huge overhead of decrypting and analyzing each packet.

Tegeler \etal in \cite{TegelerFVK12} presented BotFinder, a network-flow information based system to detect bot infections. The system uses a sequence of chronologically-ordered flow called traces to find irregularities in the network behavior between two endpoints. This along with other network metadata such as average time interval, averaged duration, average number of source and destination bytes, etc. were used as features in a local shrinking based clustering algorithm \cite{WangQZ07}. Anderson and McGrew in \cite{AndersonM17} proposed a new technique that analyzed network flow metadata and applied supervised machine learning algorithms to identify encrypted malware traffic. They used a demilitarized zone (DMZ), to collect and train the machine learning algorithm on the benign network traffic. DMZ is a sub-network that separates the externally connected services from internal systems. Externally connected services are those which connect to the internet to provide various services. As it was based on supervised learning models, it provided results which can be easily interpreted \cite{SommerP10}. The machine learning model helped in high-speed processing of the network traffic and real-time predictions. It also leveraged regularization, an important part of training, to select features that are most discriminatory \cite{HastieTF09}. Since the DMZ segregates such services and is used only in business organizations, the network traffic data collected by them is not an actual representation of the general network traffic. Since this data represents only enterprise users, i.e. those who work in business organizations, the results may not hold for general internet users such as students or home users.

This report further explores the use of network flow information as features which can be used to train machine learning algorithms. These features are obtained without decrypting any packets in the flow.